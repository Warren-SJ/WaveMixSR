{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import wavemix.sisr as sisr\n",
    "from PIL import Image\n",
    "import kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd() / \"data\"\n",
    "\n",
    "data_folder =  data_path/\"lowres_images\"\n",
    "\n",
    "output_folder =  data_path/\"output_images\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveMixSR(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        depth,\n",
    "        mult = 1,\n",
    "        ff_channel = 16,\n",
    "        final_dim = 16,\n",
    "        dropout = 0.3,\n",
    "        scale_factor = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(sisr.Level1Waveblock(mult = mult, ff_channel = ff_channel, final_dim = final_dim, dropout = dropout))\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(final_dim,int(final_dim/2), 3, stride=1, padding=1),\n",
    "            nn.Conv2d(int(final_dim/2), 1, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.path1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=scale_factor, mode='bilinear', align_corners = False),\n",
    "            nn.Conv2d(1, int(final_dim/2), 3, 1, 1),\n",
    "            nn.Conv2d(int(final_dim/2), final_dim, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.path2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=int(scale_factor), mode='bilinear', align_corners = False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "\n",
    "        y = img[:, 0:1, :, :] \n",
    "        crcb = img[:, 1:3, :, :]\n",
    "\n",
    "        y = self.path1(y)\n",
    "\n",
    "\n",
    "        for attn in self.layers:\n",
    "            y = attn(y) + y\n",
    "\n",
    "        y = self.final(y)\n",
    "\n",
    "        crcb = self.path2(crcb)\n",
    "        \n",
    "        return  torch.cat((y,crcb), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WaveMixSR(\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x Level1Waveblock(\n",
       "      (feedforward): Sequential(\n",
       "        (0): Conv2d(144, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.3, inplace=False)\n",
       "        (3): Conv2d(144, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (4): ConvTranspose2d(144, 144, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (5): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (reduction): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Conv2d(144, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(72, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (path1): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (1): Conv2d(1, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(72, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (path2): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.load('weights.pth', map_location=device)\n",
    "model = WaveMixSR(depth = 4, mult = 1, ff_channel = 144, final_dim = 144, dropout = 0.3, scale_factor = 2).to(device)\n",
    "model.load_state_dict(weights)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_target = torchvision.transforms.Compose(\n",
    "        [   torchvision.transforms.ToTensor(),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The following code is commented out because it is not needed for usage. It is only used for testing and comparison purposes.\n",
    "\n",
    "# losses = []\n",
    "# test_data_folder_tmp = data_folder\n",
    "# for image in os.listdir(test_data_folder_tmp):\n",
    "#     img = Image.open(test_data_folder_tmp/image)\n",
    "#     img = transform_target(img)\n",
    "#     img = kornia.color.rgb_to_ycbcr(img)\n",
    "#     img = img.unsqueeze(0).to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output = model(img)\n",
    "#         output = kornia.color.ycbcr_to_rgb(output)\n",
    "#         output = output.squeeze(0)\n",
    "#         output = output.to('cpu')\n",
    "#         output = output.detach().numpy()\n",
    "#         output = output.transpose(1,2,0)\n",
    "#         output = np.clip(output, 0, 1)\n",
    "#         output = (output*255).astype(np.uint8)\n",
    "#         target_image = Image.open(data_folder/image.replace('x2',''))\n",
    "#         if output.shape[0] < target_image.size[1]:\n",
    "#             output = np.pad(output, ((0, target_image.size[1] - output.shape[0]), (0, 0), (0, 0)), mode='constant')\n",
    "#         elif output.shape[0] > target_image.size[1]:\n",
    "#             output = output[:target_image.size[1], :, :]\n",
    "#         if output.shape[1] < target_image.size[0]:\n",
    "#             output = np.pad(output, ((0, 0), (0, target_image.size[0] - output.shape[1]), (0, 0)), mode='constant')\n",
    "#         elif output.shape[1] > target_image.size[0]:\n",
    "#             output = output[:, :target_image.size[0], :]\n",
    "#         loss = np.mean((np.array(target_image) - output)**2)\n",
    "#         losses.append(loss)\n",
    "#         output = Image.fromarray(output)\n",
    "#         output.save(output_folder/image)\n",
    "\n",
    "# losses_file = os.path.join(output_folder, \"losses.json\")\n",
    "# with open(losses_file, 'w') as f:\n",
    "#     json.dump(losses, f)\n",
    "    \n",
    "# average_loss = sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(data_folder):\n",
    "    img = Image.open(data_folder/image)\n",
    "    img = transform_target(img)\n",
    "    img = kornia.color.rgb_to_ycbcr(img)\n",
    "    img = img.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        output = kornia.color.ycbcr_to_rgb(output)\n",
    "        output = output.squeeze(0)\n",
    "        output = output.to('cpu')\n",
    "        output = output.detach().numpy()\n",
    "        output = output.transpose(1,2,0)\n",
    "        output = np.clip(output, 0, 1)\n",
    "        output = (output*255).astype(np.uint8)\n",
    "        output = Image.fromarray(output)\n",
    "        output.save(output_folder/image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
