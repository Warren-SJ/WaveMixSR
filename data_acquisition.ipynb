{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveMixSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt\n",
    "# Note: the above installs the requirements in the requirements.txt file. pytorch and torchvision are requirements and it would install the CPU only version of these packages. \n",
    "# If your device has a CUDA GPU, remove 'torch' and 'torchvision' from the requirements.txt file and run the cell. Then visit https://pytorch.org/ to get the appropriate \n",
    "# pytorch version with CUDA support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsr.datasets import Div2K\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data and get some insight into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path where you want to save the dataset\n",
    "data_path = Path.cwd() / \"data\"\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "dataset = Div2K(root=data_path, scale=2, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_folder = data_path/\"DIV2K/DIV2K_train_LR_bicubic/X2\"\n",
    "test_data_folder = data_path/\"DIV2K/DIV2K_valid_LR_bicubic/X2\"\n",
    "\n",
    "train_data_targest_folder = data_path/\"DIV2K/DIV2K_train_HR\"\n",
    "test_data_targest_folder = data_path/\"DIV2K/DIV2K_valid_HR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_ycbcr(image: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Convert an RGB image to YCbCr.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): RGB Image to be converted to YCbCr.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: YCbCr version of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    if not torch.is_tensor(image):\n",
    "        raise TypeError(\"Input type is not a torch.Tensor. Got {}\".format(\n",
    "            type(image)))\n",
    "\n",
    "    if len(image.shape) < 3 or image.shape[-3] != 3:\n",
    "        raise ValueError(\"Input size must have a shape of (*, 3, H, W). Got {}\"\n",
    "                         .format(image.shape))\n",
    "\n",
    "    r: torch.Tensor = image[..., 0, :, :]\n",
    "    g: torch.Tensor = image[..., 1, :, :]\n",
    "    b: torch.Tensor = image[..., 2, :, :]\n",
    "\n",
    "    delta = .5\n",
    "    y: torch.Tensor = .299 * r + .587 * g + .114 * b\n",
    "    cb: torch.Tensor = (b - y) * .564 + delta\n",
    "    cr: torch.Tensor = (r - y) * .713 + delta\n",
    "    return torch.stack((y, cb, cr), -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class for loading data\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, lr_image_folder, hr_image_folder, transform=None):\n",
    "        self.lr_image_folder = lr_image_folder\n",
    "        self.hr_image_folder = hr_image_folder\n",
    "        self.lr_image_files = os.listdir(lr_image_folder)\n",
    "        self.hr_image_files = os.listdir(hr_image_folder)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lr_image = cv2.cvtColor(cv2.imread(str(self.lr_image_folder/self.lr_image_files[idx])), cv2.COLOR_BGR2YCrCb)\n",
    "        hr_image = cv2.cvtColor(cv2.imread(str(self.hr_image_folder/self.hr_image_files[idx])), cv2.COLOR_BGR2YCrCb)\n",
    "        lr_image = torch.tensor(lr_image).permute(2, 0, 1).float() # Since OpenCV represents images as HWC and Pytorch expects them as CHW\n",
    "        hr_image = torch.tensor(hr_image).permute(2, 0, 1).float()\n",
    "        return lr_image, hr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "# Visualize random data\n",
    "\n",
    "train_dataset = CustomDataSet(lr_image_folder=train_data_folder, \n",
    "                              hr_image_folder=train_data_targest_folder,\n",
    "                              )\n",
    "# test_dataset = CustomDataSet(lr_image_folder=test_data_folder,\n",
    "#                              hr_image_folder=test_data_targest_folder)\n",
    "\n",
    "# Plot random images\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "random_indices = random.sample(range(len(train_dataset)), 16)\n",
    "fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    img = train_dataset[idx][0]\n",
    "    ax = axs[i//4, i%4]\n",
    "    ax.imshow(cv2.cvtColor(np.asarray(img.permute(1,2,0).type(torch.float32)), cv2.COLOR_YCR_CB2RGB))\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
