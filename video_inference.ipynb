{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Inference\n",
    "\n",
    "In this notebook, the wavemixSR model is used to perform video inference on a sample video. The video is first split into frames, and then each frame is passed through the model to generate a super-resolved image. The super-resolved images are then combined to form a video. This approach is not recommended as a model trained for  image super-resolution may not perform well on video data. However, this notebook is provided to demonstrate how to perform video inference using the wavemixSR model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\warre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kornia\\feature\\lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import wavemix.sisr as sisr\n",
    "import kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video1 = \"Kyoto 360p.mp4\"\n",
    "video2 = \"f1 360p.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveMixSR(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        depth,\n",
    "        mult = 1,\n",
    "        ff_channel = 16,\n",
    "        final_dim = 16,\n",
    "        dropout = 0.3,\n",
    "        scale_factor = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(sisr.Level1Waveblock(mult = mult, ff_channel = ff_channel, final_dim = final_dim, dropout = dropout))\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(final_dim,int(final_dim/2), 3, stride=1, padding=1),\n",
    "            nn.Conv2d(int(final_dim/2), 1, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.path1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=scale_factor, mode='bilinear', align_corners = False),\n",
    "            nn.Conv2d(1, int(final_dim/2), 3, 1, 1),\n",
    "            nn.Conv2d(int(final_dim/2), final_dim, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.path2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=int(scale_factor), mode='bilinear', align_corners = False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "\n",
    "        y = img[:, 0:1, :, :] \n",
    "        crcb = img[:, 1:3, :, :]\n",
    "\n",
    "        y = self.path1(y)\n",
    "\n",
    "\n",
    "        for attn in self.layers:\n",
    "            y = attn(y) + y\n",
    "\n",
    "        y = self.final(y)\n",
    "\n",
    "        crcb = self.path2(crcb)\n",
    "        \n",
    "        return  torch.cat((y,crcb), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load('weights.pth', map_location=device)\n",
    "model = WaveMixSR(depth = 4, mult = 1, ff_channel = 144, final_dim = 144, dropout = 0.3, scale_factor = 2).to(device)\n",
    "model.load_state_dict(weights)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_target = torchvision.transforms.Compose(\n",
    "        [   torchvision.transforms.ToTensor(),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_video_path, output_video_path, model, device):\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width*2, frame_height*2))\n",
    "    i = 0\n",
    "    while cap.isOpened():\n",
    "        print(i)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i == 1000:\n",
    "            break\n",
    "        frame = transform_target(frame)\n",
    "        frame = kornia.color.bgr_to_rgb(frame)\n",
    "        frame = kornia.color.rgb_to_ycbcr(frame)\n",
    "        frame = frame.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output_tensor = model(frame)\n",
    "        output_tensor = kornia.color.ycbcr_to_rgb(output_tensor)\n",
    "        output_frame = output_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy() * 255.0\n",
    "        output_frame = np.clip(output_frame, 0, 255).astype(np.uint8)\n",
    "        output_frame_bgr = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "        out.write(output_frame_bgr)\n",
    "        i = i + 1\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video(video1, \"Kyoto 720p_model.mp4\", model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video(video2, \"f1 720p_model.mp4\", model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_bicubic(input_video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width*2, frame_height*2))\n",
    "    i = 0\n",
    "    while cap.isOpened():\n",
    "        print(i)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i == 1000:\n",
    "            break\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        output_frame = cv2.resize(frame_rgb, (frame_width*2, frame_height*2), interpolation=cv2.INTER_CUBIC)\n",
    "        output_frame_bgr = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "        out.write(output_frame_bgr)\n",
    "        i = i + 1\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video_bicubic(video1, \"Kyoto 720p_bicubic.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video_bicubic(video2, \"f1 720p_bicubic.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
