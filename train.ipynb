{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import wavemix.sisr as sisr\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd() / \"data\"\n",
    "\n",
    "train_data_folder = data_path/\"DIV2K/DIV2K_train_LR_bicubic/X2\"\n",
    "test_data_folder = data_path/\"DIV2K/DIV2K_valid_LR_bicubic/X2\"\n",
    "\n",
    "train_data_targest_folder = data_path/\"DIV2K/DIV2K_train_HR\"\n",
    "test_data_targest_folder = data_path/\"DIV2K/DIV2K_valid_HR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class for loading data\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, lr_image_folder, hr_image_folder, transform=None):\n",
    "        self.lr_image_folder = lr_image_folder\n",
    "        self.hr_image_folder = hr_image_folder\n",
    "        self.lr_image_files = os.listdir(lr_image_folder)\n",
    "        self.hr_image_files = os.listdir(hr_image_folder)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lr_image = cv2.cvtColor(cv2.imread(str(self.lr_image_folder/self.lr_image_files[idx])), cv2.COLOR_BGR2YCrCb)\n",
    "        hr_image = cv2.cvtColor(cv2.imread(str(self.hr_image_folder/self.hr_image_files[idx])), cv2.COLOR_BGR2YCrCb)\n",
    "        lr_image = torch.tensor(lr_image).permute(2, 0, 1).float() # Since OpenCV represents images as HWC and Pytorch expects them as CHW\n",
    "        hr_image = torch.tensor(hr_image).permute(2, 0, 1).float()\n",
    "        return lr_image, hr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random data\n",
    "\n",
    "train_dataset = CustomDataSet(lr_image_folder=train_data_folder, \n",
    "                              hr_image_folder=train_data_targest_folder,\n",
    "                              )\n",
    "test_dataset = CustomDataSet(lr_image_folder=test_data_folder,\n",
    "                             hr_image_folder=test_data_targest_folder)\n",
    "\n",
    "# Plot random images\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "random_indices = random.sample(range(len(train_dataset)), 16)\n",
    "fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    img = train_dataset[idx][0]\n",
    "    ax = axs[i//4, i%4]\n",
    "    ax.imshow(cv2.cvtColor(np.asarray(img.permute(1,2,0).type(torch.uint8)), cv2.COLOR_YCrCb2RGB))\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveMixSR(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        depth,\n",
    "        mult = 1,\n",
    "        ff_channel = 16,\n",
    "        final_dim = 16,\n",
    "        dropout = 0.3,\n",
    "        scale_factor = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(sisr.Level1Waveblock(mult = mult, ff_channel = ff_channel, final_dim = final_dim, dropout = dropout))\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(final_dim,int(final_dim/2), 3, stride=1, padding=1),\n",
    "            nn.Conv2d(int(final_dim/2), 1, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.path1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=scale_factor, mode='bilinear', align_corners = False),\n",
    "            nn.Conv2d(1, int(final_dim/2), 3, 1, 1),\n",
    "            nn.Conv2d(int(final_dim/2), final_dim, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.path2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=int(scale_factor), mode='bilinear', align_corners = False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "\n",
    "        y = img[:, 0:1, :, :] \n",
    "        crcb = img[:, 1:3, :, :]\n",
    "\n",
    "        y = self.path1(y)\n",
    "\n",
    "\n",
    "        for attn in self.layers:\n",
    "            y = attn(y) + y\n",
    "\n",
    "        y = self.final(y)\n",
    "\n",
    "        crcb = self.path2(crcb)\n",
    "        \n",
    "        return  torch.cat((y,crcb), dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WaveMixSR(\n",
    "    depth = 4,\n",
    "    mult = 1,\n",
    "    ff_channel = 144,\n",
    "    final_dim = 144,\n",
    "    dropout = 0.3,\n",
    "    scale_factor=2\n",
    ")\n",
    "model.to(DEVICE)\n",
    "print(summary(model, input_size=(BATCH_SIZE, 3, 1000, 1000), verbose=0))\n",
    "\n",
    "\n",
    "# image = next(iter(train_loader))[0].to(DEVICE)\n",
    "# print(image.shape)\n",
    "\n",
    "# output = model(image)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:nn.Module,\n",
    "          epochs:int,\n",
    "          loss_fn:nn.Module,\n",
    "          optimizer:torch.optim.Optimizer,\n",
    "          train_loader:DataLoader,\n",
    "          device:torch.device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (lr_image, hr_image) in enumerate(train_loader):\n",
    "            lr_image, hr_image = lr_image.to(device), hr_image.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(lr_image)\n",
    "            loss = loss_fn(output, hr_image)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch: {epoch}, Batch index: {batch_idx}, Loss: {loss.item()}\")\n",
    "        torch.save(model.state_dict(), f\"model_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model=model,\n",
    "      epochs=10,\n",
    "      loss_fn=nn.HuberLoss(),\n",
    "      optimizer=torch.optim.Adam(model.parameters(), lr=0.001),\n",
    "      train_loader=train_loader,\n",
    "      device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
